{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0e44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "import laspy\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import time\n",
    "import requests\n",
    "                    \n",
    "from laserfarm import Retiler, DataProcessing, GeotiffWriter, MacroPipeline\n",
    "from laserfarm.remote_utils import get_wdclient, get_info_remote, list_remote\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404fb96",
   "metadata": {},
   "source": [
    "## Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18041536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "                    \n",
    "from dask.distributed import LocalCluster, SSHCluster \n",
    "from laserfarm import Retiler, DataProcessing, GeotiffWriter, MacroPipeline\n",
    "from laserfarm.remote_utils import get_wdclient, get_info_remote, list_remote\n",
    "\n",
    "conf_username = ''\n",
    "if 'JUPYTERHUB_USER' in os.environ:\n",
    "    conf_username = os.environ['JUPYTERHUB_USER']\n",
    "    \n",
    "\n",
    "conf_remote_path_split = pathlib.Path('/webdav/vl-laserfarm/' + conf_username + '/split')\n",
    "conf_remote_path_retiled = pathlib.Path('/webdav/vl-laserfarm/' + conf_username + '/retiled')\n",
    "conf_remote_path_norm = pathlib.Path('/webdav/vl-laserfarm/' + conf_username + '/norm')\n",
    "conf_remote_path_targets = pathlib.Path('/webdav/vl-laserfarm/' + conf_username +  '/targets')\n",
    "conf_remote_path_geotiffs = pathlib.Path('/webdav/vl-laserfarm/' + conf_username + '/geotiffs')\n",
    "conf_local_tmp = pathlib.Path('/tmp/data')\n",
    "\n",
    "\n",
    "\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "json_file_path = os.path.join(home_directory, 'laserfarm_secrets.json')\n",
    "conf_secrets_file_path = os.path.join(conf_local_tmp,'laserfarm_secrets.json')\n",
    "shutil.copy(json_file_path,conf_secrets_file_path)\n",
    "\n",
    "\n",
    "# Read variables from JSON file\n",
    "with open(conf_secrets_file_path, 'r') as json_file:\n",
    "    config_data = json.load(json_file)\n",
    "\n",
    "# Access the variables\n",
    "param_hostname = ''\n",
    "param_username = ''\n",
    "param_password = ''\n",
    "param_dataset = ''\n",
    "\n",
    "parsed_url = urlparse(param_dataset)\n",
    "\n",
    "# Extracting hostname and port\n",
    "conf_minio_server = parsed_url.hostname+':'+str(parsed_url.port)\n",
    "# Extracting the first part of the path as bucket\n",
    "path_parts = parsed_url.path.strip('/').split('/')\n",
    "conf_bucket_name = path_parts[0]\n",
    "conf_remote_path_root = '/'+'/'.join(path_parts[1:])\n",
    "\n",
    "conf_num_files = 1 \n",
    "conf_visualization_mode = 'webdav'\n",
    "param_remote_server_type = 'minio'\n",
    "\n",
    "if param_remote_server_type == 'webdav':\n",
    "    conf_remote_path_root = '/webdav/vl-laserfarm/ahn'\n",
    "elif param_remote_server_type == 'minio':\n",
    "    conf_bucket_name = 'naa-vre-public'\n",
    "    conf_remote_path_root = 'vl-laserfarm/ahn/'\n",
    "\n",
    "conf_feature_name = 'perc_95_normalized_height'\n",
    "conf_validate_precision = '0.001'\n",
    "conf_tile_mesh_size = '10.'\n",
    "conf_filter_type= 'select_equal'\n",
    "conf_attribute = 'raw_classification'\n",
    "conf_min_x = '-113107.81'\n",
    "conf_max_x = '398892.19'\n",
    "conf_min_y = '214783.87'\n",
    "conf_max_y = '726783.87'\n",
    "conf_n_tiles_side = '512'\n",
    "conf_apply_filter_value = '1'\n",
    "conf_laz_compression_factor = '7'\n",
    "param_max_filesize = '30'  # desired max file size (in bytes)\n",
    "\n",
    "\n",
    "conf_wd_opts = { 'webdav_hostname': param_hostname, 'webdav_login': param_username, 'webdav_password': param_password}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbff2bb-39bf-4cf9-880d-15e80734b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local paths\n",
    "\n",
    "conf_local_path_split = os.path.join(conf_local_tmp.as_posix(), 'split')\n",
    "conf_local_path_retiled = os.path.join(conf_local_tmp.as_posix(), 'retiled')\n",
    "conf_local_path_targets = os.path.join(conf_local_tmp.as_posix(), 'targets')\n",
    "conf_local_path_geotiff = os.path.join(conf_local_tmp.as_posix(), 'geotiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d1b76",
   "metadata": {},
   "source": [
    "## Fetching Laz Files from remote WebDAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573679af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C_01GN1.LAZ', 'C_01GZ2.LAZ', 'C_04FN2.LAZ']\n"
     ]
    }
   ],
   "source": [
    "# S1 Fetch Laz Files\n",
    "\n",
    "from minio import Minio\n",
    "\n",
    "laz_files = []\n",
    "if param_remote_server_type == 'minio':\n",
    "    minio_client = Minio(conf_minio_server, secure=True)\n",
    "    objects = minio_client.list_objects(conf_bucket_name, prefix=conf_remote_path_root, recursive=True)\n",
    "    for obj in objects:\n",
    "        if obj.object_name.lower().endswith('.laz'):\n",
    "            laz_files.append(obj.object_name.split('/')[-1])\n",
    "elif param_remote_server_type == 'webdav':\n",
    "    print(conf_remote_path_root)\n",
    "    webdva_path = conf_remote_path_root\n",
    "    laz_files = [f for f in list_remote(get_wdclient(conf_wd_opts), pathlib.Path(webdva_path).as_posix())\n",
    "                 if f.lower().endswith('.laz')]\n",
    "print(laz_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0773b1",
   "metadata": {},
   "source": [
    "## Splitting big files into smaller files before retiling\n",
    "This step can be added if the original files are too large for normal VMs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c074eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting: C_01GN1.LAZ\n",
      "Downloaded: C_01GN1.LAZ to /tmp/data/C_01GN1.LAZ\n",
      "out_filename: /tmp/data/C_01GN1-0.LAZ\n",
      "out_filename: /tmp/data/C_01GN1-1.LAZ\n",
      "out_filename: /tmp/data/C_01GN1-2.LAZ\n",
      "Splitting: C_01GZ2.LAZ\n",
      "Downloaded: C_01GZ2.LAZ to /tmp/data/C_01GZ2.LAZ\n",
      "out_filename: /tmp/data/C_01GZ2-0.LAZ\n",
      "out_filename: /tmp/data/C_01GZ2-1.LAZ\n",
      "out_filename: /tmp/data/C_01GZ2-2.LAZ\n",
      "Splitting: C_04FN2.LAZ\n",
      "Downloaded: C_04FN2.LAZ to /tmp/data/C_04FN2.LAZ\n",
      "out_filename: /tmp/data/C_04FN2-0.LAZ\n",
      "out_filename: /tmp/data/C_04FN2-1.LAZ\n",
      "out_filename: /tmp/data/C_04FN2-2.LAZ\n"
     ]
    }
   ],
   "source": [
    "# S2 split big files local minio\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def save_chunk_to_laz_file(in_filename, \n",
    "                           out_filename, \n",
    "                           offset, \n",
    "                           n_points):\n",
    "    \"\"\"Read points from a LAS/LAZ file and write them to a new file.\"\"\"\n",
    "    points = np.array([])\n",
    "    \n",
    "    with laspy.open(in_filename) as in_file:\n",
    "        with laspy.open(out_filename, \n",
    "                        mode=\"w\", \n",
    "                        header=in_file.header) as out_file:\n",
    "            in_file.seek(offset)\n",
    "            points = in_file.read_points(n_points)\n",
    "            out_file.write_points(points)\n",
    "    return out_filename\n",
    "\n",
    "def split_strategy(filename, max_filesize):\n",
    "    \"\"\"Set up splitting strategy for a LAS/LAZ file.\"\"\"\n",
    "    with laspy.open(filename) as f:\n",
    "        bytes_per_point = (\n",
    "            f.header.point_format.num_standard_bytes +\n",
    "            f.header.point_format.num_extra_bytes\n",
    "        )\n",
    "        n_points = f.header.point_count\n",
    "    n_points_target = int(\n",
    "        max_filesize * int(conf_laz_compression_factor) / bytes_per_point\n",
    "    )\n",
    "    stem, ext = os.path.splitext(filename)\n",
    "    return [\n",
    "        (filename, f\"{stem}-{n}{ext}\", offset, n_points_target)\n",
    "        for n, offset in enumerate(range(0, n_points, n_points_target))\n",
    "    ]\n",
    "\n",
    "from webdav3.client import Client\n",
    "\n",
    "client = Client(conf_wd_opts)\n",
    "# client.mkdir(conf_remote_path_split.as_posix())\n",
    "# remote_path_split = str(conf_remote_path_split)\n",
    "minio_client = Minio(conf_minio_server, secure=True)\n",
    "\n",
    "os.makedirs(conf_local_path_split, exist_ok=True)\n",
    "\n",
    "for file in laz_files:\n",
    "    print('Splitting: '+file )\n",
    "    destination_path = os.path.join(conf_local_tmp,file)\n",
    "    if param_remote_server_type == 'webdav':\n",
    "        client.download_sync(remote_path=os.path.join(conf_remote_path_root,file), local_path=destination_path)\n",
    "    elif param_remote_server_type == 'minio':\n",
    "        minio_client.fget_object(conf_bucket_name, os.path.join(conf_remote_path_root,file), destination_path)\n",
    "        print(f\"Downloaded: {file} to {destination_path}\")\n",
    "        \n",
    "    inps = split_strategy(destination_path, int(param_max_filesize)*1048576)\n",
    "    \n",
    "    for inp in inps:\n",
    "        out_filename = save_chunk_to_laz_file(*inp)\n",
    "        print('out_filename: '+out_filename)\n",
    "        split_path = os.path.join(conf_local_path_split,os.path.basename(out_filename))\n",
    "        if os.path.exists(split_path):\n",
    "            os.remove(split_path)\n",
    "        shutil.move(out_filename, conf_local_path_split)\n",
    "\n",
    "S2_done = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe5038-fb33-478c-bd4d-ca98bec5d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S21 Fetch Laz Files local\n",
    "import os\n",
    "import glob\n",
    "\n",
    "S2_done \n",
    "\n",
    "split_laz_folder = glob.glob(os.path.join(conf_local_path_split, '*.LAZ'))\n",
    "split_laz_files = []\n",
    "print(\"File names ending with .LAZ:\")\n",
    "for file_path in split_laz_folder:\n",
    "    split_laz_files.append(os.path.basename(file_path))\n",
    "\n",
    "print(split_laz_files)\n",
    "S21_done = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416e842",
   "metadata": {},
   "source": [
    "## Retiling of big files into smaller tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b489f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 Retiling local\n",
    "split_laz_files\n",
    "# remote_path_retiled = str(conf_remote_path_retiled)\n",
    "\n",
    "grid_retile = {\n",
    "    'min_x': float(conf_min_x),\n",
    "    'max_x': float(conf_max_x),\n",
    "    'min_y': float(conf_min_y),\n",
    "    'max_y': float(conf_max_y),\n",
    "    'n_tiles_side': int(conf_n_tiles_side)\n",
    "}\n",
    "\n",
    "retiling_input = {\n",
    "    # 'setup_local_fs': {'tmp_folder': conf_local_tmp.as_posix()},\n",
    "    'setup_local_fs': {\n",
    "        'input_folder': conf_local_path_split,\n",
    "        'output_folder': conf_local_path_retiled\n",
    "    },\n",
    "    # 'pullremote': conf_remote_path_split.as_posix(),\n",
    "    'set_grid': grid_retile,\n",
    "    'split_and_redistribute': {},\n",
    "    'validate': {},\n",
    "    # 'pushremote': conf_remote_path_retiled.as_posix(),\n",
    "    # 'cleanlocalfs': {}\n",
    "}\n",
    "\n",
    "for file in split_laz_files:\n",
    "    clean_file = file.replace('\"','').replace('[','').replace(']','')\n",
    "    print(clean_file)\n",
    "    # retiler = Retiler(clean_file,label=clean_file).config(retiling_input).setup_webdav_client(conf_wd_opts)\n",
    "    retiler = Retiler(clean_file,label=clean_file).config(retiling_input)\n",
    "    retiler_output = retiler.run()\n",
    "\n",
    "S3_done = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8814681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S4 Retrive retiled tiles local\n",
    "# remote_path_retiled\n",
    "\n",
    "# tiles = [t.strip('/') for t in list_remote(get_wdclient(conf_wd_opts), conf_remote_path_retiled.as_posix())\n",
    "#          if fnmatch.fnmatch(t, 'tile_*_*/')]\n",
    "S3_done \n",
    "\n",
    "tiles = []\n",
    "tile_folders = glob.glob(os.path.join(conf_local_path_retiled, 'tile_*_*'))\n",
    "\n",
    "for folder in tile_folders:\n",
    "    # Extract only the folder name without the 'conf_local_path_retiled'\n",
    "    folder_name = os.path.basename(folder)\n",
    "    tiles.append(folder_name)  # Append only the folder name\n",
    "print(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab006ce8-f290-414d-a1be-1dcd3b2f101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S5 Feature Extraction local\n",
    "\n",
    "for t in tiles:\n",
    "    local_path_targets = os.path.join(conf_local_path_targets, t)\n",
    "    features = [conf_feature_name]\n",
    "\n",
    "    tile_mesh_size = float(conf_tile_mesh_size)\n",
    "\n",
    "    grid_feature = {\n",
    "        'min_x': float(conf_min_x),\n",
    "        'max_x': float(conf_max_x),\n",
    "        'min_y': float(conf_min_y),\n",
    "        'max_y': float(conf_max_y),\n",
    "        'n_tiles_side': int(conf_n_tiles_side)\n",
    "    }\n",
    "\n",
    "    feature_extraction_input = {\n",
    "        'setup_local_fs': {\n",
    "            'input_folder': conf_local_path_retiled,\n",
    "            'output_folder': local_path_targets\n",
    "        },\n",
    "        # 'setup_local_fs': {'tmp_folder': conf_local_tmp.as_posix()},\n",
    "        # 'pullremote': conf_remote_path_retiled.as_posix(),\n",
    "        'load': {'attributes': [conf_attribute]},\n",
    "        'normalize': 1,\n",
    "        'apply_filter': {\n",
    "            'filter_type': conf_filter_type, \n",
    "            'attribute': conf_attribute,\n",
    "            'value': [int(conf_apply_filter_value)]#ground surface (2), water (9), buildings (6), artificial objects (26), vegetation (?), and unclassified (1)\n",
    "        },\n",
    "        'generate_targets': {\n",
    "            'tile_mesh_size' : tile_mesh_size,\n",
    "            'validate' : True,\n",
    "            'validate_precision': float(conf_validate_precision),\n",
    "            **grid_feature\n",
    "        },\n",
    "        'extract_features': {\n",
    "            'feature_names': features,\n",
    "            'volume_type': 'cell',\n",
    "            'volume_size': tile_mesh_size\n",
    "        },\n",
    "        'export_targets': {\n",
    "            'attributes': features,\n",
    "            'multi_band_files': False\n",
    "        },\n",
    "        # 'pushremote': conf_remote_path_targets.as_posix(),\n",
    "    #     'cleanlocalfs': {}\n",
    "    }\n",
    "    idx = (t.split('_')[1:])\n",
    "\n",
    "    # processing = DataProcessing(t, tile_index=idx,label=t).config(feature_extraction_input).setup_webdav_client(conf_wd_opts)\n",
    "    processing = DataProcessing(t, tile_index=idx,label=t).config(feature_extraction_input)\n",
    "    processing.run()\n",
    "    target_file = os.path.join(local_path_targets, conf_feature_name,t+'.ply')  \n",
    "    target_folder = os.path.join(conf_local_path_targets, conf_feature_name)\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    shutil.move(target_file, target_folder)\n",
    "    \n",
    "S5_done = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43c05f-cdd2-44e6-b745-119832689353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S6 GeoTIFF Export local\n",
    "\n",
    "S5_done\n",
    "\n",
    "# setup input dictionary to configure the GeoTIFF export pipeline\n",
    "geotiff_export_input = {\n",
    "    'setup_local_fs': {\n",
    "        'input_folder': conf_local_path_targets,\n",
    "         'output_folder': conf_local_path_geotiff\n",
    "        },\n",
    "    # 'pullremote': conf_remote_path_targets.as_posix(),\n",
    "    'parse_point_cloud': {},\n",
    "    'data_split': {'xSub': 1, 'ySub': 1},\n",
    "    'create_subregion_geotiffs': {'output_handle': 'geotiff'},\n",
    "    'pushremote': conf_remote_path_geotiffs.as_posix(),\n",
    "    # 'cleanlocalfs': {}   \n",
    "}\n",
    "\n",
    "writer = GeotiffWriter(input_dir=conf_feature_name, bands=conf_feature_name, label=conf_feature_name).config(geotiff_export_input).setup_webdav_client(conf_wd_opts)\n",
    "writer.run()\n",
    "\n",
    "remote_path_geotiffs = str(conf_remote_path_geotiffs)\n",
    "S6_done = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3a36b-9f7f-464b-8746-9d35d61de974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param vislulization\n",
    "S6_done\n",
    "\n",
    "hostname = param_hostname\n",
    "username = param_username\n",
    "password = param_password\n",
    "remote = str(conf_remote_path_geotiffs)\n",
    "num = conf_num_files\n",
    "mode = conf_visualization_mode\n",
    "output = str(conf_local_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579884fe-d05f-456e-bf2e-eea9849a05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print param\n",
    "print(hostname)\n",
    "print(username)\n",
    "print(password)\n",
    "print(remote)\n",
    "print(num)\n",
    "print(mode)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda61ce-ae9a-4d73-bf5b-b6b929d5d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_rasterio\n",
    "\n",
    "import os \n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist\n",
    "\n",
    "S6_done\n",
    "\n",
    "geo_tiff = os.path.join(conf_local_path_geotiff, 'geotiff_TILE_000_BAND_perc_95_normalized_height.tif')\n",
    "src = rasterio.open(geo_tiff)\n",
    "show(src)\n",
    "fig, ax = pyplot.subplots(1, figsize=(30, 30))\n",
    "show((src, 1), interpolation='none', ax=ax)\n",
    "show((src, 1), contour=True, ax=ax)\n",
    "pyplot.show()\n",
    "show_hist(src, bins=50, lw=0.0, stacked=False, alpha=0.3, histtype='stepfilled', title=\"Histogram\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38464582-5d52-4ca3-a51e-7d3383f3b792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
