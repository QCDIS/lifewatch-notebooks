{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d410972d-88da-4d15-996c-94b53f2299f7",
   "metadata": {},
   "source": [
    "Federated Learning development for patch-level region of interests (ROI) classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a493cc3-08e8-4221-b7e2-3450eff7063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client Training\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "input_data_path = input_data_path\n",
    "\n",
    "epochs = epochs\n",
    "\n",
    "batch_size = batch_size\n",
    "aggregator_address = aggregator_address\n",
    "\n",
    "\n",
    "\n",
    "def load_images(df_data, dir_data, input_shape):\n",
    "    \"\"\"Function to load images to study and apply preprocessing if needed.\"\"\"\n",
    "    list_images = []\n",
    "    # dir_data = dir_data + \"/patches/\"\n",
    "    dir_data = dir_data + \"/patches_client_Netherlands/\"\n",
    "    print(\"dir_data: \", dir_data)\n",
    "    for i in range(0, len(df_data)):\n",
    "        img = cv2.imread(dir_data + df_data.images[i])\n",
    "        img = cv2.resize(img, input_shape)\n",
    "        list_images.append(img)\n",
    "\n",
    "    return np.array(list_images)\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, partition_file, folder, input_shape):\n",
    "        ### START CODE HERE ###\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        df_data = pd.read_csv(folder + \"/\" + partition_file + '.csv', dtype=str, delimiter=',')\n",
    "        print(\"count values in df:\\n\", df_data['GT'].value_counts())\n",
    "        val_counts = df_data['GT'].value_counts()\n",
    "        factor = 1-(val_counts[1]/val_counts[0])\n",
    "        df_data = df_data.drop(df_data.loc[df_data['GT']=='0'].sample(frac=float(factor)).index).reset_index()\n",
    "        print(\"count values in df after balancing:\\n\", df_data['GT'].value_counts())\n",
    "        self.X = load_images(df_data, folder, self.input_shape)\n",
    "        self.Y = df_data.GT\n",
    "        self.Y = [int(el) for el in self.Y]\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        self.indexes = np.arange(0, len(self.X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Required output: length of the dataset\"\"\"\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Required input: index to access\n",
    "        Required output: image corresponding to the input index and its label\"\"\"\n",
    "        \n",
    "        image = self.X[idx]\n",
    "        label = self.Y[idx]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "def load_data(data_path, input_shape=(224,224)):\n",
    "    \"\"\"Load data (training, validation and test sets).\n",
    "    Required outputs: loaders of each set and dictionary containing the length of each corresponding set\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    trainset = CustomDataset(partition_file=\"train_client_3b\", folder=data_path, input_shape=input_shape)\n",
    "    valset = CustomDataset(partition_file=\"val_client_3\", folder=data_path, input_shape=input_shape)\n",
    "    testset = CustomDataset(partition_file=\"test_v2\", folder=data_path, input_shape=input_shape)\n",
    "    \n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    valloader = DataLoader(valset, batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=64, shuffle=True)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    num_examples = {\"trainset\" : len(trainset), \"valset\": len(valset), \"testset\" : len(testset)}\n",
    "    \n",
    "    return trainloader, valloader, testloader, num_examples\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Model architecture. Inputs in the init function can be added if needed.\"\"\"\n",
    "    def __init__(self, input_shape=(224,224), n_classes=2) -> None:\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # self.model = models.mobilenet_v2(pretrained=False)\n",
    "        # self.model.classifier[-1] = torch.nn.Linear(in_features=1280, out_features=self.n_classes)\n",
    "        # self.model = models.mobilenet_v2(pretrained=False)\n",
    "        # self.model.classifier[-1] = torch.nn.Linear(in_features=1280, out_features=self.n_classes)\n",
    "        self.model = models.vgg16(pretrained=False)\n",
    "        self.model.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=self.n_classes)\n",
    "\n",
    "        # self.model = models.vgg16(pretrained=False)\n",
    "        # self.model.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=self.n_classes)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Required input: tensor of images to predict\n",
    "        Required output: output of the model given the images tensor in input\"\"\"\n",
    "            \n",
    "        ### START CODE HERE ###\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.model(x)\n",
    "        x = torch.squeeze(x)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def train(net, trainloader, valloader, epochs):\n",
    "    \"\"\"Train the network on the training set, evaluating it on the validation set at each epoch.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss() #TODO Define loss function\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001) #TODO Define optimizer\n",
    "    \n",
    "    start = time.time()\n",
    "    for i_epoch in range(epochs):\n",
    "        ### START CODE HERE ###\n",
    "        print(\"Epoch \", i_epoch+1)\n",
    "        \n",
    "        correct, total, train_loss_epoch = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images = torch.from_numpy(np.asarray(images).astype('float32'))\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loss_iteration = criterion(outputs, labels)\n",
    "            loss_iteration.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss_epoch += loss_iteration.item()\n",
    "        \n",
    "        train_loss_epoch = train_loss_epoch / total\n",
    "        train_acc_epoch = correct / total\n",
    "        val_loss_epoch, val_acc_epoch = test(net, valloader)\n",
    "        info = \"[INFO] Epoch {}/{} - train_loss: {:.6f} - train_acc: {:.6f} - val_loss: {:.6f} - val_acc: {:.6f}\".format(\n",
    "                i_epoch + 1, epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_acc_epoch)\n",
    "        print(info + \"\\n\")\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Time to train the whole network: \", end-start, \" s\")\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    whole_labels, whole_predicted = torch.Tensor([]), torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images = torch.from_numpy(np.asarray(data[0]).astype('float32'))\n",
    "            images, labels = images.to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            whole_labels = torch.cat((whole_labels.cpu(), labels.cpu()))\n",
    "            whole_predicted = torch.cat((whole_predicted.cpu(), predicted.cpu()))\n",
    "    print(\"CONFUSION MATRIX:\")\n",
    "    print(confusion_matrix(whole_labels.cpu(), whole_predicted.cpu()))\n",
    "    accuracy = correct / total\n",
    "    loss = loss / total\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "net = Model().to(DEVICE)\n",
    "s1 = time.time()\n",
    "trainloader, valloader, testloader, num_examples = load_data(input_data_path)\n",
    "print(\"time to load the data for this client: \", time.time()-s1)\n",
    "\n",
    "class HistologyClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainloader, valloader, testloader, num_examples) -> None:\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.testloader = testloader\n",
    "        self.num_examples = num_examples\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        train(self.model, self.trainloader, self.valloader, epochs=epochs)\n",
    "        return self.get_parameters(), self.num_examples[\"trainset\"], {}\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.model, self.testloader)\n",
    "        print(\"==== loss, accuracy\", loss, accuracy)\n",
    "        return float(loss), self.num_examples[\"testset\"], {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "client = HistologyClient(net, trainloader, valloader, testloader, num_examples)\n",
    "fl.client.start_numpy_client(aggregator_address, client=client, grpc_max_message_length=895_870_912)\n",
    "finish_time = time.time()\n",
    "\n",
    "print(\"==== TOTAL TIME TO TRAIN THE FEDERATION: \", finish_time-start_time)\n",
    "print(\"FINISHED\")\n",
    "loss, acc = test(client.model, client.testloader)\n",
    "print(\"FINAL MODEEEEL: \")\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5a673-b3b3-49f8-8d59-e8eddda10815",
   "metadata": {},
   "source": [
    "Server-side aggregation strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926557f5-0845-4aa9-b694-9f9e85d79206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server Aggregation-0\n",
    "import flwr as fl\n",
    "\n",
    "batch_size = \n",
    "def get_on_fit_config_fn():\n",
    "    \"\"\"Return a function which returns training configurations.\"\"\"\n",
    "\n",
    "    def fit_config(rnd: int):\n",
    "        \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
    "        config = {\n",
    "            \"learning_rate\": str(0.001),\n",
    "            \"batch_size\": str(32),\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    return fit_config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,\n",
    "    fraction_eval=1,\n",
    "    min_fit_clients=2,\n",
    "    min_available_clients=2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(),\n",
    ")\n",
    "fl.server.start_server(server_address=\"[::]:8080\", config={\"num_rounds\": 3}, strategy=strategy, grpc_max_message_length=895_870_912)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac0f5a-1739-416d-8d40-81bc52e4e7b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73307c44-a91f-4e30-b641-0ceda897f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server Aggregation-1\n",
    "import flwr as fl\n",
    "\n",
    "aggregator_address = aggregator_address\n",
    "num_rounds = num_rounds\n",
    "\n",
    "def get_on_fit_config_fn():\n",
    "    \"\"\"Return a function which returns training configurations.\"\"\"\n",
    "\n",
    "    def fit_config(rnd: int):\n",
    "        \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
    "        config = {\n",
    "            \"learning_rate\": str(0.001),\n",
    "            \"batch_size\": str(32),\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    return fit_config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,\n",
    "    fraction_eval=1,\n",
    "    min_fit_clients=2,\n",
    "    min_available_clients=2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(),\n",
    ")\n",
    "# fl.server.start_server(server_address=\"[::]:8080\", config={\"num_rounds\": 3}, strategy=strategy, grpc_max_message_length=895_870_912)\n",
    "fl.server.start_server(server_address=aggregator_address, config={\"num_rounds\": num_rounds}, strategy=strategy, grpc_max_message_length=895_870_912)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
